ETL Pipeline Notes

JSON: File format with key/value pair. Looks similar to a python dictionary. 
    [{"ID" : "P1622","region":"North"}]

XML (Extensible Markup Language): Very similar to HTML in terms of formatting. However
in XML tags can be tailored to the data set.
    <Entry>
        <ID>PI22</ID>
        <Region>North</Region>

Example API call for the world bank:
url = 'http://api.worldbank.org/v2/countries/ch/indicators/SP.RUR.TOTL/?format=json&date=1995:2001'
r = requests.get(url)
r.json()

This request gets the rural population of Switzerland from 1995 to 2001.

Converting data types
* Ex: pd.to_numeric() Other options: [to_datetime, to_timedelta]
* Ex: dataFrame['fieldName].asType()

Parsing Dates:
parsed_date = pd.to_datetime('January 1st, 2017')
parsed_date -> You can access the month,year,second as [parsed_date.month, parsed_date.year, parsed_date.second]

You can specify how you want pandas to read in your date field:
parsed_date = pd.to_datetime('5/3/2017 5:30', format='%m/%d/%Y %H:%M')
parsed_date.month => 5

*NOTE* When calling .replace make sure to add .str before the .replace call.

Example of plotting totalAmt by year.
ax = df_projects.groupby('approvalyear')['totalamt'].sum().plot(x='approvalyear', y='totalamt',
                                title ='Total Amount Approved per Year')

Encoding : Set of rules mapping string characters to binary representation.

Code to determine the encoding of a dataset:

from encodings.aliases import aliases
alias_values = set(aliases.values())
for alias in set(aliases.values()):
    try:
        pd.read_csv('mystery.csv', encoding=alias)
    except:
        pass

Alternate way using the chardet package

import chardet
# use the detect method to find the encoding
# 'rb' means read in the file as binary
with open("mystery.csv", 'rb') as file:
    print(chardet.detect(file.read()))

Handling missing values
    1) Delete the data:
        a) Large amount of missing data
        b) Features you don't suspect to be important.
    2) Imputation (substitution)
        a) Mean: Fill in data using the column mean.
        b) Backward/Forward: Works for ordered or time series data. Use neighboring cells to fill in the data.

1) Fill in missing values with mean of column. 
df_melt['GDP_filled'] = df_melt.groupby('Country Name')['GDP'].transform(lambda x: x.fillna(x.mean()))
2) Example of backward filling (ffil = forward filling)
df_melt['GDP_bfill'] = df_melt.sort_values('year').groupby('Country Name')['GDP'].fillna(method = "bfill")

Data duplication

*NOTE* here is how to make a date for comparison => datetime.date(1980, 2, 1)

Dummy Variables

***Categorical variables have no order, so assigning [1,2,3,4] in a column is a bad idea.***

Code to remove a character patterm from a string
https://medium.com/factory-mind/regex-tutorial-a-simple-cheatsheet-by-examples-649dc1c3f285

Interesting formula
sector.loc[sector['sector1_aggregates'].str.contains('Energy', re.IGNORECASE).replace(np.nan, False),'sector1_aggregates'] = 'Energy'

How to find outliers
1) How to find them?
    a) Can use data visualizations if you are working with one dimensional data.
    b) Statistical methods (z-scores, Tukey method)
        i) Tukey Method : 
            Find the first quartile (ie .25 quantile)
            Find the third quartile (ie .75 quantile)
            Calculate the inter-quartile range (Q3 - Q1)
            Any value that is greater than Q3 + 1.5 * IQR is an outlier
            Any value that is less than Qe - 1.5 * IQR is an outlier
    c) Machine learning techniques (PCA, Clustering methods)
2) What to do with them?
    a) 

Extract the first quartile:
    population_2016['population'].quantile(0.25)
Finding the max Tukey value
    max_value = Q3 + 1.5 * IQR

Find values in first set but not second.
    list(set(population_outliers['Country Name']) - set(gdp_outliers['Country Name']))

Function that implements the Tukey rule
def tukey_rule(data_frame, column_name):
    data = data_frame[column_name]
    Q1 = data.quantile(0.25)
    Q3 = data.quantile(0.75)

    IQR = Q3 - Q1

    max_value = Q3 + 1.5 * IQR
    min_value = Q1 - 1.5 * IQR

    return data_frame[(data_frame[column_name] < max_value) & (data_frame[column_name] > min_value)]

Scaling data (Normalization)
* Some ML models need to have the same distribution for data. 
1) Rescaling: Scale data so it fits [0,1] distribution
    distribution stays the same, range changes.
2) Standardization: Mean of zero, standardized deviation of one.
    General distribution stays the same, mean and sd have been standardized.

Normalized Class: 
    class Normalizer():
    # TODO: Complete the normalizer class
    # The normalizer class receives a dataframe as its only input for initialization
    # For example, the data frame might contain gdp and population data in two separate columns
    # Follow the TODOs in each section
    
    def __init__(self, dataframe):
        
        # TODO: complete the init function. 
        # Assume the dataframe has an unknown number of columns like [['gdp', 'population']] 
        # iterate through each column calculating the min and max for each column
        # append the results to the params attribute list
        
        # For example, take the gdp column and calculate the minimum and maximum
        # Put these results in a list [minimum, maximum]
        # Append the list to the params variable
        # Then take the population column and do the same
        
        # HINT: You can put your x_min_max() function as part of this class and use it
        
        # HINT: Use a for loop to iterate through the columns of the dataframe
        
        for col in dataframe.colums()
        
        self.params = []
            
    def x_min_max(data):
        # TODO: complete the x_min_max method
        # HINT: You can use the same function defined earlier in the exercise
        minimum = None
        maximum = None
        return minimum, maximum

    def normalize_data(self, x):
        # TODO: complete the normalize_data method
        # The function receives a data point as an input and then outputs the normalized version
        # For example, if an input data point of [gdp, population] were used. Then the output would
        # be the normalized version of the [gdp, population] data point
        # Put the results in the normalized variable defined below
        
        # Assume that the columns in the dataframe used to initialize an object are in the same
        # order as this data point x
        
        # HINT: You cannot use the normalize_data function defined earlier in the exercise.
        # You'll need to iterate through the individual values in the x variable. A for loop and the 
        #    Python enumerate method might be useful.
        # Use the params attribute where the min and max values are stored 
        normalized = []
        return normalized

Feature Engineering: 

Example Feature Engineering Function:
    # TODO: Fill out the create_multiples function.
# The create_multiples function has two inputs. A floating point number and an integer.
# The output is a list of multiples of the input b starting from the square of b and ending at b^k.

def create_multiples(b, k):
    
    new_features = []
    
    # TODO: use a for loop to make a list of multiples of b: ie b^2, b^3, b^4, etc... until b^k
    for i in range(2,k+1):
        new_features.append(b ** i)
    
    return new_features

# TODO: Fill out the column_name_generator function.
# The function has two inputs: a string representing a column name and an integer k. 
# The 'k' variable is the same as the create_multiples function.
# The output should be a list of column names.
# For example if the inputs are ('gdp', 4) then the output is a list of strings ['gdp2', 'gdp3', gdp4']
def column_name_generator(colname, k):
    
    col_names = []
    for i in range(2,k+1):
        col_names.append('{}{}'.format(colname, i))
    return col_names

# TODO: Fill out the concatenate_features function.
# The function has three inputs. A dataframe, a column name represented by a string, and an integer representing
# the maximum power to create when engineering features.

# If the input is (df_2016, 'gdp', 3), then the output will be the df_2016 dataframe with two new columns
# One new column will be 'gdp2' ie gdp^2, and then other column will be 'gdp3' ie gdp^3.

# HINT: There may be more than one way to do this.
# The TODOs in this section point you towards one way that works
def concatenate_features(df, column, num_columns):
    
    # TODO: Use the pandas apply() method to create the new features. Inside the apply method, you
    # can use a lambda function with the create_mtuliples function
    new_features = df[column].apply(lambda x: create_multiples(x, num_columns))
    
    # TODO: Create a dataframe from the new_features variable
    # Use the column_name_generator() function to create the column names
    
    # HINT: In the pd.DataFrame() method, you can specify column names inputting a list in the columns option
    # HINT: Using new_features.tolist() might be helpful
    new_features_df = pd.DataFrame(new_features.tolist(), columns = column_name_generator(column, num_columns))
    
    # TODO: concatenate the original date frame in df with the new_features_df dataframe
    # return this concatenated dataframe
    return pd.concat([df, new_features_df], axis=1)

Load : Store the data in a database
1) Storing data to a sql server
    conn = sqlite3.connect('worldbank.db')
    df_merged.to_sql('merged', con = conn, if_exists='replace', index=False)

2) Example of how to create an SQL table with a primary key: 
    cur.execute("CREATE TABLE population (countryname TEXT, countrycode TEXT, year INTEGER, population REAL, PRIMARY KEY (countrycode, year));")
Insert into SQL table
    sql_string = 'INSERT INTO projects (project_id, countryname, countrycode, totalamt, year) VALUES ("{}", "{}", "{}", {}, {});'.format(project_id, countryname, countrycode, totalamt, year)


